# Universal RAG System - Architecture Overview

## ğŸ—ï¸ Modular Architecture

This project follows a **clean, modular architecture** with separation of concerns for maintainability and scalability.

---

## ğŸ“‚ Directory Structure

```
rag-based/
â”‚
â”œâ”€â”€ app.py                      # Flask web application entry point
â”œâ”€â”€ watcher.py                  # File monitoring service entry point
â”œâ”€â”€ config.py                   # System configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ venv/                       # Python 3.12 virtual environment
â”‚
â”œâ”€â”€ models/                     # Data models (Domain layer)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ document.py             # Document and DocumentChunk classes
â”‚
â”œâ”€â”€ core/                       # Business logic (Service layer)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py             # DatabaseManager - ChromaDB operations
â”‚   â”œâ”€â”€ llm.py                  # LLMService - Ollama interactions
â”‚   â””â”€â”€ processor.py            # FileProcessor - Orchestrates extraction
â”‚
â”œâ”€â”€ extractors/                 # Text extraction (Utility layer)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_extractor.py        # PDF text extraction
â”‚   â”œâ”€â”€ image_extractor.py      # OCR for images
â”‚   â”œâ”€â”€ audio_extractor.py      # Speech-to-text
â”‚   â”œâ”€â”€ document_extractor.py   # DOCX, TXT extraction
â”‚   â””â”€â”€ code_extractor.py       # Code files extraction
â”‚
â”œâ”€â”€ utils/                      # Helper functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py           # File operations (hash, type detection)
â”‚   â””â”€â”€ text_utils.py           # Text processing (chunking, cleaning)
â”‚
â”œâ”€â”€ templates/                  # Frontend
â”‚   â””â”€â”€ index.html              # Web interface
â”‚
â””â”€â”€ data/                       # Data storage
    â”œâ”€â”€ incoming/               # Upload folder
    â”œâ”€â”€ sorted/                 # Organized by category
    â””â”€â”€ database/               # ChromaDB persistent storage
```

---

## ğŸ”„ Application Flow

### File Processing Flow (watcher.py)

```
1. Watchdog detects new file in data/incoming/
   â†“
2. FileProcessor.extract_text()
   â”œâ”€â†’ PDFExtractor (for PDFs)
   â”œâ”€â†’ ImageExtractor (for images via OCR)
   â”œâ”€â†’ AudioExtractor (for audio via speech-to-text)
   â”œâ”€â†’ DocumentExtractor (for DOCX, TXT)
   â””â”€â†’ CodeExtractor (for code files)
   â†“
3. LLMService.classify_content()
   - Uses Ollama to categorize content
   â†“
4. FileProcessor.create_chunks()
   - TextUtils.chunk_text() splits into 500-char chunks
   â†“
5. DatabaseManager.add_chunks()
   - Stores in ChromaDB with metadata
   â†“
6. File moved to data/sorted/{Category}/
```

### Query Flow (app.py)

```
1. User submits query via web interface
   â†“
2. DatabaseManager.query()
   - Semantic search in ChromaDB
   - Returns top 4 relevant chunks
   â†“
3. LLMService.generate_response()
   - Builds strict RAG prompt
   - Calls Ollama with context
   - Extracts citations
   â†“
4. Response returned to user with:
   - Answer text
   - Cited filenames
   - Download links
```

---

## ğŸ§© Component Details

### Models Layer (`models/`)

**Purpose**: Define data structures

**Components**:
- `Document`: Represents a processed file
  - filename, filepath, file_hash, category, text_content, etc.
- `DocumentChunk`: Represents a text chunk
  - chunk_id, text, metadata for ChromaDB

**Why**: Clean data contracts, type safety, easy serialization

---

### Core Layer (`core/`)

**Purpose**: Business logic and services

#### DatabaseManager (`database.py`)
- **Responsibilities**:
  - Initialize ChromaDB client
  - Add document chunks
  - Query for relevant chunks
  - Delete chunks by file hash
- **Dependencies**: chromadb, models.DocumentChunk

#### LLMService (`llm.py`)
- **Responsibilities**:
  - Classify content into categories
  - Generate strict RAG responses
  - Check Ollama availability
- **Dependencies**: ollama

#### FileProcessor (`processor.py`)
- **Responsibilities**:
  - Orchestrate text extraction
  - Create Document objects
  - Create DocumentChunk objects
- **Dependencies**: extractors, utils, models

---

### Extractors Layer (`extractors/`)

**Purpose**: File format-specific text extraction

Each extractor is **single-responsibility**:
- `PDFExtractor`: Uses pdfminer.six
- `ImageExtractor`: Uses pytesseract (OCR)
- `AudioExtractor`: Uses SpeechRecognition + pydub
- `DocumentExtractor`: Uses python-docx, plain text readers
- `CodeExtractor`: Plain text for code files

**Why**: Easy to add new file types, isolated dependencies

---

### Utils Layer (`utils/`)

**Purpose**: Reusable helper functions

#### FileUtils (`file_utils.py`)
- `get_file_hash()`: MD5 hash for deduplication
- `get_file_type()`: Categorize file by extension
- `list_zip_contents()`: Extract ZIP metadata

#### TextUtils (`text_utils.py`)
- `chunk_text()`: Split text into fixed-size chunks
- `clean_text()`: Normalize whitespace

---

## ğŸ¯ Design Principles

### 1. **Separation of Concerns**
- Each module has ONE clear responsibility
- No business logic in extractors
- No file I/O in LLM service

### 2. **Dependency Injection**
- Services passed as parameters
- Easy to mock for testing
- Configuration externalized

### 3. **Single Responsibility Principle**
- Each class/function does ONE thing well
- Easy to understand, modify, test

### 4. **Open/Closed Principle**
- Easy to add new extractors without modifying core
- New file types = new extractor class

### 5. **DRY (Don't Repeat Yourself)**
- Common logic extracted to utils
- Reusable components

---

## ğŸ”Œ Extension Points

### Adding a New File Type

1. Create extractor in `extractors/`:
```python
# extractors/excel_extractor.py
import pandas as pd

class ExcelExtractor:
    @staticmethod
    def extract(filepath):
        df = pd.read_excel(filepath)
        return df.to_string()
```

2. Update `FileProcessor.extract_text()`:
```python
elif file_type == 'spreadsheet':
    return self.excel_extractor.extract(filepath)
```

3. Update `FileUtils.get_file_type()`:
```python
'spreadsheet': ['.xlsx', '.xls', '.csv']
```

### Adding a New Feature

- **Custom chunking strategy**: Modify `TextUtils.chunk_text()`
- **Different LLM**: Modify `LLMService.__init__(model=...)`
- **Additional metadata**: Extend `Document` model
- **New API endpoint**: Add route in `app.py`

---

## ğŸ§ª Testing Strategy

### Unit Tests
- Test each extractor independently
- Mock file I/O
- Test edge cases (empty files, corrupt files)

### Integration Tests
- Test DatabaseManager with real ChromaDB
- Test LLMService with Ollama
- Test full processing pipeline

### Example Test Structure
```
tests/
â”œâ”€â”€ test_extractors.py
â”œâ”€â”€ test_database.py
â”œâ”€â”€ test_llm.py
â”œâ”€â”€ test_processor.py
â””â”€â”€ test_utils.py
```

---

## ğŸš€ Performance Optimizations

### Current
- Synchronous processing
- File-by-file

### Future Enhancements
1. **Async Processing**
   - Use `asyncio` for parallel extraction
   - Process multiple files simultaneously

2. **Batch Database Inserts**
   - Collect chunks, insert in batches
   - Reduce ChromaDB overhead

3. **Caching**
   - Cache file hashes to avoid reprocessing
   - Cache LLM classifications

4. **Streaming**
   - Stream large file processing
   - Chunked reading for big PDFs

---

## ğŸ”’ Security Considerations

1. **Input Validation**
   - Validate file types before processing
   - Limit file sizes
   - Sanitize filenames

2. **Path Traversal Protection**
   - Use `Path` for safe path operations
   - Validate destination paths

3. **Resource Limits**
   - Limit chunk size
   - Timeout on long operations

---

## ğŸ“Š Scalability

### Vertical Scaling
- More RAM â†’ More documents in ChromaDB
- Faster CPU â†’ Faster LLM inference
- SSD â†’ Faster file I/O

### Horizontal Scaling
- Multiple watcher instances (different folders)
- Load balancer for Flask app
- Distributed ChromaDB (future)

---

## ğŸ› ï¸ Development Workflow

1. **Local Development**
   ```bash
   python -m venv venv
   .\venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Run Services**
   ```bash
   # Terminal 1
   python watcher.py
   
   # Terminal 2
   python app.py
   ```

3. **Code Style**
   - Follow PEP 8
   - Use type hints where possible
   - Document public functions

---

## ğŸ“– References

- **Flask**: https://flask.palletsprojects.com/
- **ChromaDB**: https://docs.trychroma.com/
- **Ollama**: https://ollama.ai/
- **Watchdog**: https://python-watchdog.readthedocs.io/

---

**Last Updated**: December 10, 2025  
**Python Version**: 3.12  
**Architecture**: Modular, Service-Oriented
